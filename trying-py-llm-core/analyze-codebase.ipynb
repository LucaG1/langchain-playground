{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TODO:\n",
    "- need to install every thing on Windows\n",
    "- Error with c++ building llama-cpp-python"
   ],
   "id": "9c43acb5e2652cc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class LowLevelModule:\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "@dataclass\n",
    "class HighLevelModule:\n",
    "    name: str\n",
    "    description: str\n",
    "    sub_modules: List[LowLevelModule]\n",
    "\n",
    "@dataclass\n",
    "class SoftwareArchitecture:\n",
    "    system_prompt = \"You are a software architect\"\n",
    "    prompt = \"\"\"\n",
    "    Code base:\n",
    "    {code_base}\n",
    "    ----\n",
    "\n",
    "    Analyze this code base and carefully write a description of\n",
    "    the software architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    modules: List[HighLevelModule]\n",
    "\n",
    "    def to_markdown(self) -> str:\n",
    "        lines = [\n",
    "            f\"# {self.name}\\n\",\n",
    "            f\"\\n{fill(self.description, width=60)}\\n\\n\",\n",
    "        ]\n",
    "        for module in self.modules:\n",
    "            lines.append(f\"## {module.name}\\n\\n\")\n",
    "            lines.append(\n",
    "                f\"**Description:** {fill(module.description, width=60)}\\n\\n\"\n",
    "            )\n",
    "            lines.append(\"### Sub-modules\\n\\n\")\n",
    "            for sub_module in module.sub_modules:\n",
    "                lines.append(f\"**{sub_module.name}**\\n\\n\")\n",
    "                lines.append(f\"{fill(sub_module.description, width=60)}\\n\\n\")\n",
    "        return \"\".join(lines)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    repo_url = \"https://github.com/advanced-stack/llm-components\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        clone_dir = Path(temp_dir) / \"repo\"\n",
    "        clone_repository(repo_url, clone_dir)"
   ],
   "id": "58788e6523c362d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llm_components.loaders.code_base import map_codebase_to_text\n",
    "\n",
    "code_base = map_codebase_to_text(clone_dir)"
   ],
   "id": "aa990eede4916362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with OpenAIAssistant(SoftwareArchitecture, model='gpt-4o') as assistant:\n",
    "    software_architecture = assistant.process(code_base=code_base)\n",
    "    markdown_output = software_architecture.to_markdown()\n",
    "    print(markdown_output)"
   ],
   "id": "55f4511c635ec56e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
